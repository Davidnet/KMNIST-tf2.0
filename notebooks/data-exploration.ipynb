{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "\n",
    "SEED = 2712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"/data/kmnist-train-imgs.npz\") as img_container, \\\n",
    "     np.load(\"/data/kmnist-train-labels.npz\") as labels_container:\n",
    "    images = img_container[\"arr_0\"]\n",
    "    labels = labels_container[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert images.shape[0] == labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmnist_ds = tf.data.Dataset.from_tensor_slices((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0624 02:11:45.432312 139833587656512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "kmnist_ds = kmnist_ds.shuffle(70000, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmnist_train_ds = kmnist_ds.skip(1000)\n",
    "kmnist_dev_ds = kmnist_ds.take(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 6 with image in shapes (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in kmnist_dev_ds:\n",
    "    print(f\"label: {y} with image in shapes {x.shape}\")\n",
    "    plt.imshow(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in kmnist_dev_ds:\n",
    "    img_example = x\n",
    "    label_example = y\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_tensor = tf.io.serialize_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = _bytes_feature(serialized_tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_proto = feature.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\xa2\\x06\\n\\x9f\\x06\\x08\\x04\\x12\\x08\\x12\\x02\\x08\\x1c\\x12\\x02\\x08\\x1c\"\\x90\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x12\\x8e\\xde\\xff\\xf2p\\t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0c\\xab\\xff\\xff\\xfaG\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x1e\\xaf\\xfb\\xff\\xff\\xf34\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00^\\xc8\\xfe\\xf9\\xff\\xff\\xf3.\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x008\\x97\\xec\\xfd\\xb2u\\xff\\xff\\xffI\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x87\\xff\\xff\\xc1\\x0b#\\xff\\xff\\xf38\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x91\\xff\\xffX\\x00H\\xfe\\xff\\xf4?\\x02\\x1a>\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xae\\xff\\xfeG\\x10\\xae\\xff\\xff\\xff\\xca\\x9e\\xee\\xff\\xa4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x84\\xff\\xff\\xf4\\xe9\\xf8\\xff\\xff\\xff\\xff\\xfe\\xff\\xe0A\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00Y\\xfd\\xff\\xff\\xf8\\xfd\\xff\\xff\\xff\\xff\\xfe\\xa7\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x11\\xa8\\x9e\\xc1\\xe7\\xfe\\xff\\xff\\xff\\xfe\\x95\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1a\\xdc\\xff\\xff\\xff\\xba\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x9b\\xee\\xff\\xff\\xff\\xcd\\x07\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x89\\xfb\\xf2\\xdb\\x9e\\xff\\xfb\\xe1\\xc0$\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00W\\xf7\\x9e!5\\x7f\\xff\\xff\\xff\\xff\\x9f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\xda\\xfd\\xb8R\\x13\\xa5\\xff\\xff\\xff\\xf3k\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c\\xf6\\xff\\xfc\\xfd\\xeb\\xfa\\xff\\xfd\\xa1(\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x17\\xd2\\xfe\\xf6\\xff\\xfb\\xfc\\xff\\xf3\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x1c\\x86t\\x8aP\\xd0\\xff\\xec\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\xb5\\xff\\xfd{9&\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x070\\xcc\\xed\\xff\\xff\\xff\\xff\\xf7N\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0b\\xca\\xf5\\xf8\\xe9\\xfc\\xff\\xff\\xff\\xff\\xc0\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15\\xed\\xcd\\xb6\\xe2\\xea\\xfd\\xff\\xff\\xff\\xcd\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00(\\xeb\\xfe\\xfe\\xff\\xfd\\xd3\\xfc\\xff\\xff\\x93\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x8a\\xfd\\xf3\\xff\\xfe\\xdf\\'\\xf0\\xff\\xfcJ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\xd6\\xff\\xff\\xff\\xff\\xfa\\xc2\\xff\\xff\\xca\\r\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00/\\x88\\xca\\xff\\xff\\xf2\\xed\\xff\\xf8<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01-x\\xb6E\\xd2\\xfe\\xae\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_proto = tf.reshape(feature_proto, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf_feature_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected serialized to be a vector, got shape: [] [Op:ParseExample]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-3da1e36d7ac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_feature_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_example_v2\u001b[0;34m(serialized, features, example_names, name)\u001b[0m\n\u001b[1;32m    805\u001b[0m   outputs = _parse_example_raw(\n\u001b[1;32m    806\u001b[0m       \u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       dense_types, dense_defaults, dense_shapes, name)\n\u001b[0m\u001b[1;32m    808\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_construct_sparse_tensors_for_sparse_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36m_parse_example_raw\u001b[0;34m(serialized, names, sparse_keys, sparse_types, dense_keys, dense_types, dense_defaults, dense_shapes, name)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mdense_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mdense_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0msparse_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_parsing_ops.py\u001b[0m in \u001b[0;36mparse_example\u001b[0;34m(serialized, names, sparse_keys, dense_keys, dense_defaults, sparse_types, dense_shapes, name)\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_defaults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0msparse_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             ctx=_ctx)\n\u001b[0m\u001b[1;32m    593\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_parsing_ops.py\u001b[0m in \u001b[0;36mparse_example_eager_fallback\u001b[0;34m(serialized, names, sparse_keys, dense_keys, dense_defaults, sparse_types, dense_shapes, name, ctx)\u001b[0m\n\u001b[1;32m    684\u001b[0m                              \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_attr_Nsparse\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                              \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_inputs_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m    687\u001b[0m   _execute.record_gradient(\n\u001b[1;32m    688\u001b[0m       \"ParseExample\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected serialized to be a vector, got shape: [] [Op:ParseExample]"
     ]
    }
   ],
   "source": [
    "tf.io.parse_example(tf_feature_proto.numpy(), feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SkipDataset shapes: ((28, 28), ()), types: (tf.uint8, tf.uint8)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmnist_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
