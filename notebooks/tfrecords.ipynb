{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes_list {\n",
      "  value: \"test_string\"\n",
      "}\n",
      "\n",
      "bytes_list {\n",
      "  value: \"test_bytes\"\n",
      "}\n",
      "\n",
      "float_list {\n",
      "  value: 2.7182817459106445\n",
      "}\n",
      "\n",
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n",
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_bytes_feature(b'test_string'))\n",
    "print(_bytes_feature(u'test_bytes'.encode('utf-8')))\n",
    "\n",
    "print(_float_feature(np.exp(1)))\n",
    "\n",
    "print(_int64_feature(True))\n",
    "print(_int64_feature(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x12\\x06\\n\\x04T\\xf8-@'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = _float_feature(np.exp(1))\n",
    "\n",
    "feature.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of observations in the dataset\n",
    "n_observations = int(1e4)\n",
    "\n",
    "# boolean feature, encoded as False or True\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "\n",
    "# integer feature, random from 0 .. 4\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "\n",
    "# string feature\n",
    "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
    "feature2 = strings[feature1]\n",
    "\n",
    "# float feature, from a standard normal distribution\n",
    "feature3 = np.random.randn(n_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'cat', b'dog', b'cat', ..., b'chicken', b'cat', b'cat'],\n",
       "      dtype='|S7')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "  \"\"\"\n",
    "  Creates a tf.Example message ready to be written to a file.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "  # data type.\n",
    "  \n",
    "  feature = {\n",
    "      'feature0': _int64_feature(feature0),\n",
    "      'feature1': _int64_feature(feature1),\n",
    "      'feature2': _bytes_feature(feature2),\n",
    "      'feature3': _float_feature(feature3),\n",
    "  }\n",
    "  \n",
    "  # Create a Features message using tf.train.Example.\n",
    "  \n",
    "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "  return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_example = serialize_example(False, 4, b'goat', 0.9876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_proto = tf.train.Example.FromString(serialized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"feature0\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature1\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 4\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature2\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"goat\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature3\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 0.9876000285148621\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=115, shape=(), dtype=bool, numpy=False>, <tf.Tensor: id=116, shape=(), dtype=int64, numpy=0>, <tf.Tensor: id=117, shape=(), dtype=string, numpy=b'cat'>, <tf.Tensor: id=118, shape=(), dtype=float64, numpy=-1.7982914546647135>)\n"
     ]
    }
   ],
   "source": [
    "for element in features_dataset:\n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-9a367125515c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialize_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \"\"\"\n\u001b[1;32m   1142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3224\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3225\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3226\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3227\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   3228\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2589\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2590\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2593\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1366\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1367\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1542\u001b[0m         self._function_attributes)\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                           converted_func)\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2583\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2584\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-e4531739750a>\u001b[0m in \u001b[0;36mserialize_example\u001b[0;34m(feature0, feature1, feature2, feature3)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   feature = {\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0;34m'feature0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_int64_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0;34m'feature1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_int64_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;34m'feature2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_bytes_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "features_dataset.map(serialize_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), (), (), ()), types: (tf.bool, tf.int64, tf.string, tf.float64)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_seralize_example(f0, f1, f2, f3):\n",
    "    tf_string = tf.py_function(\n",
    "                                serialize_example,\n",
    "                                (f0, f1, f2, f3),\n",
    "                                tf.string)\n",
    "    return tf.reshape(tf_string, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sereliazed_ds = features_dataset.map(tf_seralize_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0624 06:49:01.697157 140674179516160 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n",
      "W0624 06:49:01.698336 140674179516160 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    }
   ],
   "source": [
    "tf.data.experimental.TFRecordWriter(\"test.tfrecord\").write(sereliazed_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1036\r\n",
      "-rw-r--r-- 1 root root    9215 Jun 24 02:27 data-exploration.ipynb\r\n",
      "-rw-r--r-- 1 root root 1004055 Jun 24 06:49 test.tfrecord\r\n",
      "-rw-r--r-- 1 root root   38329 Jun 24 06:43 tfrecords.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset([\"test.tfrecord\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: id=90207, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04j.\\xe6\\xbf'>\n",
      "<tf.Tensor: id=90209, shape=(), dtype=string, numpy=b'\\nQ\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03dog\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xd2\\\\\\x0c?\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x01'>\n",
      "<tf.Tensor: id=90211, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\x1e\\xc37\\xbf'>\n",
      "<tf.Tensor: id=90213, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xa7\\x81\\xd4\\xbe'>\n",
      "<tf.Tensor: id=90215, shape=(), dtype=string, numpy=b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xb3\\xef~?'>\n",
      "<tf.Tensor: id=90217, shape=(), dtype=string, numpy=b'\\nU\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x17\\n\\x08feature2\\x12\\x0b\\n\\t\\n\\x07chicken\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04M\\xeae\\xbe'>\n",
      "<tf.Tensor: id=90219, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xc8\\xa0\\xda\\xbe'>\n",
      "<tf.Tensor: id=90221, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xb8\\x11\\x1c\\xbf'>\n",
      "<tf.Tensor: id=90223, shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03dog\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04w\\xf6\\xce\\xbe'>\n",
      "<tf.Tensor: id=90225, shape=(), dtype=string, numpy=b'\\nQ\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03dog\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xab\\xeb\\x1e\\xbf\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x01'>\n"
     ]
    }
   ],
   "source": [
    "for raw_record in raw_dataset.take(10):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.  \n",
    "feature_description = {\n",
    "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset = raw_dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {feature0: (), feature1: (), feature2: (), feature3: ()}, types: {feature0: tf.int64, feature1: tf.int64, feature2: tf.string, feature3: tf.float32}>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature0': <tf.Tensor: id=90260, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90261, shape=(), dtype=int64, numpy=0>, 'feature2': <tf.Tensor: id=90262, shape=(), dtype=string, numpy=b'cat'>, 'feature3': <tf.Tensor: id=90263, shape=(), dtype=float32, numpy=-1.7982914>}\n",
      "{'feature0': <tf.Tensor: id=90268, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90269, shape=(), dtype=int64, numpy=1>, 'feature2': <tf.Tensor: id=90270, shape=(), dtype=string, numpy=b'dog'>, 'feature3': <tf.Tensor: id=90271, shape=(), dtype=float32, numpy=0.5482913>}\n",
      "{'feature0': <tf.Tensor: id=90276, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90277, shape=(), dtype=int64, numpy=0>, 'feature2': <tf.Tensor: id=90278, shape=(), dtype=string, numpy=b'cat'>, 'feature3': <tf.Tensor: id=90279, shape=(), dtype=float32, numpy=-0.717821>}\n",
      "{'feature0': <tf.Tensor: id=90284, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90285, shape=(), dtype=int64, numpy=0>, 'feature2': <tf.Tensor: id=90286, shape=(), dtype=string, numpy=b'cat'>, 'feature3': <tf.Tensor: id=90287, shape=(), dtype=float32, numpy=-0.41505167>}\n",
      "{'feature0': <tf.Tensor: id=90292, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90293, shape=(), dtype=int64, numpy=4>, 'feature2': <tf.Tensor: id=90294, shape=(), dtype=string, numpy=b'goat'>, 'feature3': <tf.Tensor: id=90295, shape=(), dtype=float32, numpy=0.995845>}\n",
      "{'feature0': <tf.Tensor: id=90300, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90301, shape=(), dtype=int64, numpy=2>, 'feature2': <tf.Tensor: id=90302, shape=(), dtype=string, numpy=b'chicken'>, 'feature3': <tf.Tensor: id=90303, shape=(), dtype=float32, numpy=-0.2245266>}\n",
      "{'feature0': <tf.Tensor: id=90308, shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: id=90309, shape=(), dtype=int64, numpy=0>, 'feature2': <tf.Tensor: id=90310, shape=(), dtype=string, numpy=b'cat'>, 'feature3': <tf.Tensor: id=90311, shape=(), dtype=float32, numpy=-0.4270079>}\n",
      "{'feature0': <tf.Tensor: id=90316, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90317, shape=(), dtype=int64, numpy=0>, 'feature2': <tf.Tensor: id=90318, shape=(), dtype=string, numpy=b'cat'>, 'feature3': <tf.Tensor: id=90319, shape=(), dtype=float32, numpy=-0.60964537>}\n",
      "{'feature0': <tf.Tensor: id=90324, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90325, shape=(), dtype=int64, numpy=1>, 'feature2': <tf.Tensor: id=90326, shape=(), dtype=string, numpy=b'dog'>, 'feature3': <tf.Tensor: id=90327, shape=(), dtype=float32, numpy=-0.40422413>}\n",
      "{'feature0': <tf.Tensor: id=90332, shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: id=90333, shape=(), dtype=int64, numpy=1>, 'feature2': <tf.Tensor: id=90334, shape=(), dtype=string, numpy=b'dog'>, 'feature3': <tf.Tensor: id=90335, shape=(), dtype=float32, numpy=-0.6207835>}\n"
     ]
    }
   ],
   "source": [
    "for parse_record in parsed_dataset.take(10):\n",
    "    print(repr(parse_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"python_saver.tfrecords\") as writer:\n",
    "    for i in range(n_observations):\n",
    "        example = serialize_example(feature0[i], feature1[i], feature2[i], feature3[i])\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2028\r\n",
      "drwxr-xr-x 3 1000 1000    4096 Jun 24 07:33 .\r\n",
      "drwxr-xr-x 1 root root    4096 Jun 24 01:38 ..\r\n",
      "drwxr-xr-x 2 root root    4096 Jun 24 04:38 .ipynb_checkpoints\r\n",
      "-rw-r--r-- 1 root root    9215 Jun 24 02:27 data-exploration.ipynb\r\n",
      "-rw-r--r-- 1 root root 1004055 Jun 24 07:34 python_saver.tfrecords\r\n",
      "-rw-r--r-- 1 root root 1004055 Jun 24 06:49 test.tfrecord\r\n",
      "-rw-r--r-- 1 root root   33422 Jun 24 07:33 tfrecords.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(\"/data/kmnist_dev.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset = raw_dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset = parsed_dataset.map(lambda x: tf.io.parse_tensor(x[\"image_raw\"], tf.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: <unknown>, types: tf.uint8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in img_dataset.take(1):\n",
    "    plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
